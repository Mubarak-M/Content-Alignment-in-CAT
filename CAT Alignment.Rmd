---
title: "Evaluating Content Alignment in Computerized Adaptive Testing"
author: "Wise, S. L., et al. (2015)"
output:
  xaringan::moon_reader:
    css: ["default", "../svm-xaringan-style.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(dev = 'svg')
options(device = function(file, width, height) {
  svg(tempfile(), width = width, height = height)
})
library(tidyverse)
library(stevemisc)
```



class: center, middle
# 
## Goal

.center[** Highlights  the process of evaluating content alignment in adaptive test.**] 
---
# Content Alignment
##  Fixed Form and CAT
Degree of agreement between the standards and the test content

--
## CAT
Appropriate level of challenge for test taker
---

# Traditional Alignment Process

--
- Use of explicit
criteria and report on how these criteria are acceptably or unacceptably met for specific standards and a particular
test form (Rothman, Slattery, Vranek, & Resnick, 2002;Webb, 1997)

<br>
<br>


--
- Use of alignment index
that represents the degree of the overall alignment for the
test form with the full set of standards (Polikoff, Porter, &
Smithson, 2011; Porter, 2002)

<br>
<br>

--
 .center[**Evaluators examine and review items on a test form**]
---

# Challenges of Traditional Alignment Process

--
- No common test form to evaluate

<br>

--
- Reviewing item pool is impractical

<br>

--
- Test event and item pool may no be comparable
---


# Alignment information

### The Item Pool
The successful implementation of any CAT is largely dependent on the adequacy of its item pool.

<br>
--
**Meta-tags**

- Tags of sample items are evaluated for accuracy to avoid mismatch between meta-tag and content attributes.  

<br>

--
**Size and Content Distribution**   

- The distribution of item difficulty values is adequate for
assessing examinees across a specified range of achievement
levels.  

-  The number of items is sufficient to satisfy any
requirements for both score precision and managing item exposure. 

---

# Alignment information

### The Item Selection Algorithm
The item selection algorithm is crucial to a CAT’s implementation of the test plan.

<br>
--
**Challenge**

- Algorithm may be written in code that is challenging to interpret.
- Algorithm may be viewed by the test developer as intellectual property that is proprietary

<br>

--
**Work Around**   

The evaluator
may need to use the documentation of the algorithm rather
than the algorithm itself to understand the processes used to
control content for the test
---

# Alignment information

### The Test Event Records
The most direct way to evaluate alignment with a CAT is to examine the records from actual test events.

<br>
Because there will typically be a large number of unique test events, the evaluator will need to examine a sample of test events that is large enough to allow the identification of unusual content patterns and diverse enough to cover the range of student outcomes.
---

# CAT Alignment Framework

### Potential Threats to Alignment

-  The test plan may inadequately sample the content domain.

- The item meta-tags may be inaccurate.

-  The item pool may be inadequate, either in numbers of items or range of difficulty.

<br>

--
**Examining Threats**
1. Test Plan

2. Item Pool

3. Test Event Records
---

# Evaluating the Test Plan
The alignment evaluator will review the test plan that was established by the test owner
and provide an assessment of the test plan alignment.

<br>
--
.center[** To be completed before CAT program become operational**]
<br>
<br>
--
1. Are the elements of the assessment all included in the content domain?

2. Do the elements of the assessment represent a broad cross-section of the content domain?

3. Are important elements of the content domain absent from the test plan?
---

# Evaluation the Item Pool

How capable is the item pool to provide well-aligned test events.

<br>

--

This will provide useful information regarding the vulnerability of
the item pool to the alignment threat of meta-data misspecification.

<br>

--
As a rule of thumb, it is recommended that the item sample consist of at least 20% of the pool at each
grade level or minimum of 100 items (whichever is larger).

<br>

--
The alignment evaluator should also assess the item pool’s vulnerability to the alignment threats of inadequate pool
depth and inadequate difficulty range.
---

# Evaluating Test Event Records

1. Item-by-item history of that test event.

2. Sequence of each item administered and it's difficulty.

3. The correctness of the response to that item.

4. The examinee’s provisional achievement estimate after that item had been scored.

5.  The examinee’s final achievement estimate along with its standard error.

<br>

<br>
--
.center[**Review of test records should provide an overall indicator as to whether and what extent the CAT was affected by alignment threats**]
---

# Content Alignment Indicators

### CA (Index of Content Alignment) 
Content alignment for a test event can be quantified by comparing the numbers of items from each content unit with
the numbers specified by the test plan.

<br>

.center[![](https://github.com/Mubarak-M/Content-Alignment-in-CAT/blob/main/slides/fig/CA.png?raw=TRUE)]

$n_i$: The number of items administered from the ith unit.  

$s_i$: The number of items that should have been administered from that unit  

k: The total number of content units  

L: The number of items administered in this particular test event.
---

# Content Alignment Indicators

### CA (Index of Content Alignment) 

$CA_j$ will equal 1.0 if the test event was perfectly aligned, with values less than 1.0 
to the degree to which there is misalignment.
---

# Content Alignment Indicators

### DM (Index of Difficulty Mismatch) 
A test event’s difficulty alignment can be quantified by comparing the difficulty of an administered item with the
examinee’s provisional achievement estimate at the point at which the item was selected.


.center[![](https://github.com/Mubarak-M/Content-Alignment-in-CAT/blob/main/slides/fig/DM.png?raw=TRUE)]

$\hat\theta_i$: The examinee’s provisional achievement
estimate prior to selecting item i.  

$b_i$: The difficulty of the ith item.  

$\sigma$: The standard deviation of trait level estimates.   

L: The test length for the current test.
---

# Content Alignment Indicators

### DM (Index of Difficulty Mismatch)

The lowest attainable value of $DM_j$ is .0, corresponding to
a CAT whose items were perfectly matched to the provisional
achievement estimate at each item selection.  

Interpreting $DM_j$ values above zero is similar to interpreting z-scores.  

A $DM_j$ value of .3 would indicate an average difference of .3
standard deviations of item difficulty from the targeted trait
level estimate. 
---

# Application on Fixed Adaptive Test Plan

**Test**  
- Operational adaptive test designed to measure the state education standards in mathematics in a Southeastern U.S. state.

- 7,619 sixth-grade students in the 2012–2013 school year.  

- Five content areas.  

- The CAT had a fixed length of 50 items, and selected items from a pool of 1,700 candidate items.

- The hypothetical test plan devised for this example assumes that each test will include 10 items for each content strand.
---

# Result

.center[![](https://github.com/Mubarak-M/Content-Alignment-in-CAT/blob/main/slides/fig/Result1.png?raw=TRUE)]


--
-  32 test events had content alignment index values less than .70.

-  12 were from students having achievement level estimates at or below the fifth percentile of students in the sixth grade.

-  15 were from students having achievement level estimates at or above the 95th percentile. 

-  5 were from students scattered throughout the achievement distribution.
---

# Summary

- Provided framework for evaluating content alignment in CAT.

- Highlighted challenges faced in conducting CAT alignment evaluation.

- Raised concerns about the need to address how to identify the degree to which an item is representative
of a content area, and which other content areas it is related to.

- Raised concern about how much misalignment can be tolerated in a CAT test event without validity being unacceptably compromised?


