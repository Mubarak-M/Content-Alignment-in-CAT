<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Evaluating Content Alignment in Computerized Adaptive Testing</title>
    <meta charset="utf-8" />
    <meta name="author" content="Wise, S. L., et al. (2015)" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="../svm-xaringan-style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Evaluating Content Alignment in Computerized Adaptive Testing
### Wise, S. L., et al. (2015)

---






class: center, middle
# 
## Goal

.center[** Highlights  the process of evaluating content alignment in adaptive test.**] 
---
# Content Alignment
##  Fixed Form and CAT
Degree of agreement between the standards and the test content

--
## CAT
Appropriate level of challenge for test taker
---

# Traditional Aliggnment Process

--
- Use of explicit
criteria and report on how these criteria are acceptably or unacceptably met for specific standards and a particular
test form (Rothman, Slattery, Vranek, &amp; Resnick, 2002;Webb, 1997)

&lt;br&gt;
&lt;br&gt;


--
- Use of alignment index
that represents the degree of the overall alignment for the
test form with the full set of standards (Polikoff, Porter, &amp;
Smithson, 2011; Porter, 2002)

&lt;br&gt;
&lt;br&gt;

--
 .center[**Evaluators examine and review items on a test form**]
---

# Challenges of Traditional Alignment Process

--
- No common test form to evaluate

&lt;br&gt;

--
- Reviewing item pool is impractical

&lt;br&gt;

--
- Test event and item pool may no be comparable
---

# Testing Algorith and Content Alignment

The item selection algorithm choose items of appropriate difficulty while satisfying content constraints.

---

# Alignment information

### The Item Pool
The successful implementation of any CAT is largely dependent on the adequacy of its item pool.

&lt;br&gt;
--
**Meta-tags**

- Tags of sample items are evaluated for accuracy to avoid mismatch between meta-tag and content attributes.  

&lt;br&gt;

--
**Size and Content Distribution**   

- The distribution of item difficulty values is adequate for
assessing examinees across a specified range of achievement
levels.  

-  The number of items is sufficient to satisfy any
requirements for both score precision and managing item exposure. 

---

# Alignment information

### The Item Selection Algorithm
The item selection algorithm is crucial to a CAT’s implementation of the test plan.

&lt;br&gt;
--
**Challenge**

- Algorithm may be written in code that is challenging to interpret.
- Algorithm may be viewed by the test developer as intellectual property that is proprietary

&lt;br&gt;

--
**Work Around**   

The evaluator
may need to use the documentation of the algorithm rather
than the algorithm itself to understand the processes used to
control content for the test
---

# Alignment information

### The Test Event Records
The most direct way to evaluate alignment with a CAT is to examine the records from actual test events.

&lt;br&gt;
Because there will typically be a large number of unique test events, the evaluator will need to examine a sample of test events that is large enough to allow the identification of unusual content patterns and diverse enough to cover the range of student outcomes.
---

# CAT Alignment Framework

### Potential Threats to Alignment

-  The test plan may inadequately sample the content domain.

- The item meta-tags may be inaccurate.

-  The item pool may be inadequate, either in numbers of items or range of difficulty.

&lt;br&gt;

--
**Examining Threats**
1. Test Plan

2. Item Pool

3. Test Event Records
---

# Evaluating the Test Plan
The alignment evaluator will review the test plan that was established by the test owner
and provide an assessment of the test plan alignment.

&lt;br&gt;
--
.center[** To be completed before CAT program become operational**]
&lt;br&gt;
&lt;br&gt;
--
1. Are the elements of the assessment all included in the content domain?

2. Do the elements of the assessment represent a broad cross-section of the content domain?

3. Are important elements of the content domain absent from the test plan?
---

# Evaluation the Item Pool

How capable is the item pool to provide well-aligned test events.

&lt;br&gt;

--

This will provide useful information regarding the vulnerability of
the item pool to the alignment threat of meta-data misspecification.

&lt;br&gt;

--
As a rule of thumb, it is recommended that the item sample consist of at least 20% of the pool at each
grade level or minimum of 100 items (whichever is larger).

&lt;br&gt;

--
The alignment evaluator should also assess the item pool’s vulnerability to the alignment threats of inadequate pool
depth and inadequate difficulty range.
---

# Evaluating Test Event Records

1. Item-by-item history of that test event.

2. Sequence of each item administered and it's difficulty.

3. The correctness of the response to that item.

4. The examinee’s provisional achievement estimate after that item had been scored.

5.  The examinee’s final achievement estimate along with its standard error.

&lt;br&gt;

&lt;br&gt;
--
.center[**Review of test records should provide an overall indicator as to whether and what extent the CAT was affected by alignment threats**]
---

# Content Alignment Indicators
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
